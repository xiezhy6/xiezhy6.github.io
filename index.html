<!DOCTYPE html>
<head>
    <title>Zhenyu Xie</title>
    <meta name="author" content="Zhenyu Xie">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta property="og:title" content="Zhenyu Xie">
	<meta property="og:description" content="PhD student, Sun Yat-sen University">
    <meta property="og:image" content="https://nicklashansen.github.io/files/me.png">
	<meta property="og:url" content="https://xiezhy6.github.io/">
	<meta name="twitter:card" content="summary_large_image">
    <link rel="apple-touch-icon" href="files/12.jpg">
    <link rel="icon" type="image/jpg" href="files/12.jpg">
    <link rel="manifest" href="files/site.webmanifest">
    <link rel="stylesheet" href="style.css">
</head>

<div class="header noselect">
    <div class="content row">
        <div class="header-profile-picture"></div>
        <div class="header-text">
            <div class="header-name">
                <h1>Zhenyu Xie</h1>
            </div>
            <div class="header-subtitle">
                PhD student, Sun Yat-sen University
            </div>
            <div class="header-links">
                <a class="btn" href="#contact">Email</a> /
                <a class="btn" href="https://scholar.google.com/citations?user=a6D7UxwAAAAJ&hl=en">Google Scholar</a> /
                <a class="btn" href="https://github.com/xiezhy6">GitHub</a> /
                <!-- <a class="btn" href="https://twitter.com/ncklashansen">Twitter</a> / -->
                <!-- <a class="btn" href="https://www.linkedin.com/in/ncklas">LinkedIn</a> / -->
                <a class="btn" href="files/cv.pdf">CV</a>
            </div>
        </div>
    </div>
</div>
<div class="content" style="padding-bottom: 64px;">
    <div>
        <p>
            I am a PhD student at <a href="https://www.sysu.edu.cn/sysuen/">Sun Yat-sen University</a>, advised by Prof. <a href="https://lemondan.github.io/">Xiaodan Liang</a> 
            at <a href="https://www.sysu-hcp.net/">Human Cyber Physical Intelligence Integration Lab (HCP-I2 Lab)</a>. 
            I am currently a visting PhD student in the Robotics Institute at <a href="https://www.cmu.edu/">Carnegie Mellon University</a>, advised by Prof. <a href="https://www.cs.cmu.edu/~ftorre/">Fernando de la Torre</a>.
            I was a research intern at <a href="https://www.bytedance.com/en/">ByteDance</a> and <a href="https://www.tencent.com/en-us/">Tencent</a> during my PhD study.
            Before starting my PhD, I received my BS and MS degrees from <a href="https://www.sysu.edu.cn/sysuen/">Sun Yat-sen University</a>, 
            advised by Prof. <a href="https://cse.sysu.edu.cn/content/2498">Jianhuang Lai</a> and Prof. <a href="https://cse.sysu.edu.cn/content/2478">Xiaohua Xie</a>.
            My research interests lie in human-centric 2D/3D modeling and 3D generative model.
            Currently, I am focusing on high-fidelty 3D human reconstruction and single image to 3D generation.
        </p>
    </div>

    <div class="section-spacing">
        <div>
            <h2 class="noselect">Recent Activities</h2>
            <ul>
            <li class="list-item-spacing" ><span class="bold">[07/2024]</span> &nbsp; One paper (First author) about image-based 3D virtual try-on is accepted by <a href="">ACM MM 2024</a>.</li>
            <li class="list-item-spacing" ><span class="bold">[01/2024]</span> &nbsp; One paper about text-to-motion synthesis is accepted by <a href="https://arxiv.org/pdf/2401.02142">TVCG 2024</a>.</li>
            <li class="list-item-spacing" ><span class="bold">[12/2023]</span> &nbsp; One paper (First author) about text-to-motion synthesis is accepted by <a href="https://arxiv.org/pdf/2312.10960">AAAI 2024</a>.</li>
            <li class="list-item-spacing" ><span class="bold">[11/2023]</span> &nbsp; Glad to serve as a visiting scholar in the Robotics Institute at CMU.</li>
            <li class="list-item-spacing" ><span class="bold">[03/2023]</span> &nbsp; One paper (First author) about general purpose garment-to-person virtual try-on is accepted by <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_GP-VTON_Towards_General_Purpose_Virtual_Try-On_via_Collaborative_Local-Flow_Global-Parsing_CVPR_2023_paper.pdf">CVPR 2023</a>.</li>
            <li class="list-item-spacing" ><span class="bold">[09/2022]</span> &nbsp; One paper about hard pose person-to-person virtual try-on is accepted by <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/d3221cdb27e49d9c1cd35ad254feccfe-Paper-Conference.pdf">NeurIPS 2022</a>.</li>
            <li class="list-item-spacing" ><span class="bold">[06/2022]</span> &nbsp; One paper about cross-modal fashion image synthesis is accepted by <a href="https://arxiv.org/pdf/2208.05621">ACM MM 2022</a>.</li>
            <li class="list-item-spacing" ><span class="bold">[03/2022]</span> &nbsp; One paper about in-the-wild person-to-person virtual try-on is accepted by <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Dressing_in_the_Wild_by_Watching_Dance_Videos_CVPR_2022_paper.pdf">CVPR 2022</a>.</li>
            <li class="list-item-spacing" ><span class="bold">[10/2021]</span> &nbsp; One paper (First author) about unpaired person-to-person virtual try-on is accepted by <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/151de84cca69258b17375e2f44239191-Paper.pdf">NeurIPS 2021</a>.</li>
            <li class="list-item-spacing" ><span class="bold">[10/2021]</span> &nbsp; One paper (Co-first author) about dance video synthesis is accepted by <a href="https://arxiv.org/pdf/2110.14147">TIP 2021</a>.</li>
            <li class="list-item-spacing" ><span class="bold">[8/2021]</span> &nbsp; One paper about image-based 3D virtual try-on is accepted by <a href="https://arxiv.org/pdf/2108.00386">ICCV 2021</a>.</li>
            <li class="list-item-spacing" ><span class="bold">[7/2021]</span> &nbsp; One paper (First author) about Neural Architecture Search for garment-to-person virtual try-on is accepted by <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_M3D-VTON_A_Monocular-to-3D_Virtual_Try-On_Network_ICCV_2021_paper.pdf">ACM MM 2021</a>.</li>
            <!-- Add more list items here if needed -->
            </ul>
        </div>
        </div>

    <div>
        <h2 class="noselect">Publications and preprints</h2>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(files/dreamvton.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="">DreamVTON: Customizing 3D Virtual Try-on with Personalized Diffusion Models</a><br/>
                <span class="bold">Zhenyu Xie</span>, Haoye Dong, Yufei Gao, Zehua Ma, Xiaodan Liang<br/>
                <span class="italic">ACM MM</span>, 2024<br/>
                <a class="btn btn-red" href="">arXiv</a> / <a class="btn" href="">code</a> / <a class="btn btn-dark" href="">bibtex</a>
            </div>
        </div>

        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(files/guess.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="">GUESS:GradUally Enriching SyntheSis for Text-Driven Human Motion Generation</a><br/>
                Xuehao Gao, Yang Yang, <span class="bold">Zhenyu Xie</span>, Shaoyi Du, Zhongqian Sun, Yang Wu<br/>
                <span class="italic">TCVG</span>, 2024<br/>
                <a class="btn btn-red" href="https://arxiv.org/pdf/2401.02142">arXiv</a> / <a class="btn" href="https://github.com/Xuehao-Gao/GUESS">code</a> / <a class="btn btn-dark" href="">bibtex</a>
            </div>
        </div>

    </div>

    <div class="noselect">
        <a id="contact"></a>
        <h2>Contact</h2>
        You are very welcome to contact me regarding my research. I typically respond within a few days.<br/>
        I can be contacted directly at <span class="bold">hello</span> [at] <span class="bold">nicklashansen</span>.com
    </div>
</div>
<div class="footer noselect">
    <div class="footer-content">
        &copy; 2024 Nicklas Hansen. No web trackers. Design is my own. You are welcome to fork it <a style="color: white; text-decoration: underline;" href="https://github.com/nicklashansen/nicklashansen.github.io">here</a>.
    </div>
</div>
